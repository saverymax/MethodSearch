{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo as pm\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "item selector to grab feature I want to work with in pipe.\n",
    "\n",
    "see http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html#sphx-glr-auto-examples-hetero-feature-union-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    For data grouped by feature, select subset of data at a provided key.\n",
    "    \"\"\"\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        return df[self.column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class title_featurer(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class for creating custom title feature\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Init custom feature\n",
    "        \"\"\"\n",
    "\n",
    "        with open('constant_lists/section_lists_custom_dict.json') as f:\n",
    "            label_lists = json.load(f)\n",
    "\n",
    "        self.label_list = label_lists['methods']\n",
    "\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        \"\"\"\n",
    "        fit method just returns the data\n",
    "        \"\"\"\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"\n",
    "        See if the title is in the list jim gave me and give it a weight if so\n",
    "        \"\"\"\n",
    "\n",
    "        title_vector = []\n",
    "        pattern = r'(?<=<title>)(.*?)(?=<\\/title>)'\n",
    "        #for index, row in df.iterrows():\n",
    "        for row in df:\n",
    "            regex_search = re.search(pattern, row)\n",
    "            #if regex_search:\n",
    "                #print(regex_search.group(0))\n",
    "            if regex_search.group(0) in self.label_list:\n",
    "                title_vector.append(1)\n",
    "            else:\n",
    "                title_vector.append(0)\n",
    "\n",
    "        X = np.array([title_vector]).T # need the transpose to convert from [1,32000] to [32000,1]\n",
    "\n",
    "        return X\n",
    "        #return title_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "location feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class location_featurer(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class for creating custom location feature\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        \"\"\"\n",
    "        fit method just returns the data\n",
    "        \"\"\"\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, column):\n",
    "        \"\"\"\n",
    "        See if the title is in the list jim gave me and give it a weight if so\n",
    "        \"\"\"\n",
    "        \n",
    "        location_vector = column.round(1)\n",
    "        # round location\n",
    "        X = np.array([location_vector]).T # need the transpose to convert from [1,32000] to [32000,1]\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape (38909, 7)\n"
     ]
    }
   ],
   "source": [
    "client = pm.MongoClient('localhost', 27017)\n",
    "db = client['full_texts'] # creates database if not there\n",
    "#documents = db['texts'] # creates new collection if not there\n",
    "documents = db['train_val_v2']\n",
    "#df = pd.DataFrame(list(documents.find()))\n",
    "#df.fillna(value = 'none', inplace = True)\n",
    "\n",
    "df_conclusion = pd.DataFrame(list(documents.find({'label': 'conclusion'}).limit(10000)))\n",
    "df_result = pd.DataFrame(list(documents.find({'label': 'result'}).limit(10000)))\n",
    "df_method = pd.DataFrame(list(documents.find({'label': 'method'}).limit(10000)))\n",
    "df_intro = pd.DataFrame(list(documents.find({'label': 'introduction'}).limit(10000)))\n",
    "\n",
    "dfs = [df_conclusion, df_result, df_method, df_intro]\n",
    "\n",
    "# merge the dfs!\n",
    "merged_df = pd.concat(dfs)\n",
    "merged_df.sort_values('date', inplace = True)\n",
    "\n",
    "# drop short rows\n",
    "merged_df = merged_df.loc[merged_df['text'].map(len) > 400]\n",
    "merged_df.reset_index(inplace = True, drop = True)\n",
    "print(\"df shape\", merged_df.shape)\n",
    "\n",
    "# Make data binary\n",
    "pattern = r'^(?!method).*$'\n",
    "merged_df['label'].replace(pattern, 'other', regex = True, inplace = True)\n",
    "\n",
    "# clean punctuation...\n",
    "#punctuation = r'[\\*\\<\\>\\?\\.\\$\\!\\(\\)\\@\\#\\%\\^\\-\\+\\{\\}\\[\\]\\,\\\\\\/:;\"\\'\\|]'\n",
    "\n",
    "# reset indices so I can use the indices from X_test and y_predictions\n",
    "X_train = merged_df.loc[:31999, ['text', 'location']].reset_index(drop=True)\n",
    "y_train = merged_df.loc[:31999, 'label'].reset_index(drop=True)\n",
    "X_test = merged_df.loc[32000:, ['text', 'location']].reset_index(drop=True)\n",
    "y_test = merged_df.loc[32000:, 'label'].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small dataset for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.sample(200)\n",
    "X = merged_df.loc[:, ['text', 'location']]\n",
    "y = merged_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well I want to use a location feature but I need a more complex pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            ('location_pipe', Pipeline([\n",
    "                ('selector', ItemSelector(column='location')),\n",
    "                ('location', location_featurer()),\n",
    "            ])),\n",
    "\n",
    "            ('title_pipe', Pipeline([\n",
    "                ('selector', ItemSelector(column='text')),\n",
    "                ('title', title_featurer()),\n",
    "            ])),\n",
    "            \n",
    "            ('text_pipe', Pipeline([\n",
    "                ('selector', ItemSelector(column='text')),\n",
    "                ('tfidf', TfidfVectorizer()),  \n",
    "            ])),\n",
    "            \n",
    "        ],\n",
    "#     transformer_weights={\n",
    "#         'titles': .8,\n",
    "#         'location': 1.2,\n",
    "#         'tfidf': .7\n",
    "#         }\n",
    "    )),\n",
    "\n",
    "    # Use a SVC classifier on the combined features\n",
    "    #('svcl', SVC(kernel='linear')),\n",
    "    ('lg', LogisticRegression(random_state=0)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test this pipe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     method       0.94      0.96      0.95      1278\n",
      "      other       0.99      0.99      0.99      5631\n",
      "\n",
      "avg / total       0.98      0.98      0.98      6909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
