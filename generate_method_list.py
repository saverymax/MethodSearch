import json
import re
import operator
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import method_constants

"""
Script to generate list of all the ways to say method, using the tag_text_counts.json,
as generated by tag_text.py. I could just check for matches to method and materials, which I did. Or try to match all strings in method_constants, which isn't very helpful
"""

def clean_methods(process):
    """
    Decorator of process_strings
    """

    def wrapper(method_constants):
        """
        Wrapper of process_strings
        Just testing wrapper. This is unecessary!
        """

        new_methods = process(method_constants)
        stop = stopwords.words('english')
        new_methods = [i.lower() for i in new_methods]
        new_methods = [i for i in new_methods if i not in stop]

        return new_methods

    return wrapper

@clean_methods
def process_strings(method_constants):
    """
    Tokenize method constants
    """

    tokenized_methods = [word_tokenize(method) for method in method_constants]
    flattened_list = [word for method in tokenized_methods for word in method]

    return flattened_list

# new_method_sec = process_strings(method_constants.sections)
# new_method_titles = process_strings(method_constants.titles)
#
# new_method_constants = list(set(new_method_sec + new_method_titles))

with open("tag_text_counts.json") as f:
    textfile = json.load(f)

method_list = {}
material_list = {}

# print(sorted(textfile.items(), key=operator.itemgetter(1), reverse = True))
#
# Check the tag text for any matches to the tokenized constants
# print(new_method_constants)
for key in textfile:
# not working properly
#     for constant in new_method_constants:
#         method = re.search(constant, key.lower())
#         if method != None:
#             print(method, key)
#             key_new = re.sub('\s+',' ', key)
#             method_list.append((key_new.lower().strip(), textfile[key]))

    method = re.search("method", key.lower())
    if method != None:
        keynew = re.sub('\s+',' ', key)
        method_list[keynew] = textfile[key]
        #method_list.append(key.lower().strip())

    material = re.search("material", key.lower())
    if material != None:
        keynew  = re.sub('\s+',' ', key)
        method_list[keynew] = textfile[key]
        #material_list.append(key.lower().strip())
        #print(method.group(0))

# if using lists...
#methods = list(set(method_list + material_list))
#methods = list(set(method_list))
# also works
# third = list(set(first) | set(second))

#print(methods)

# for us with lists
# with open("method_material_dictionary_custom.txt", "a+", encoding='utf-8') as f:
#     try:
#         for key in methods:
#             f.write("{}\n".format(key))
#     except BaseException as e:
#         print(e, key)

print(method_list)
sorted_method_dict = sorted(method_list.items(), key=operator.itemgetter(1), reverse = True)

# for use with dicts
with open("method_material_dictionary_custom.json", "w") as f:
    json.dump(sorted_method_dict, f, separators=(',', ': '), indent=2), #sort_keys=True)
